from fastapi import APIRouter, HTTPException, Depends
from models.schemas import PredictionInput, PredictionOutput
from core.logging_config import setup_logger
from db.database import db_config
from db.repositories import PredictionRepository
from typing import Protocol, runtime_checkable
from sqlalchemy.orm import Session

router = APIRouter(prefix="/predict", tags=["predictions"])
logger = setup_logger(__name__)

# --- Abstracci√≥n para el principio Liskov ---
@runtime_checkable
class IPredictionService(Protocol):
    async def predict(self, input_data: PredictionInput) -> PredictionOutput:
        ...

# Implementaci√≥n concreta compatible con LSP
class LDAPredictionService:
    def __init__(self, model_repository: PredictionRepository):
        self.repository = model_repository
    
    async def predict(self, input_data: PredictionInput) -> PredictionOutput:
        """Implementaci√≥n espec√≠fica para modelo LDA"""
        logger.info("üîç Procesando predicci√≥n con modelo LDA...")
        # Aqu√≠ ir√≠a tu l√≥gica actual de make_prediction()
        prediction_data = {
            "probability": 0.85,  # Ejemplo
            "risk_level": "high"
        }
        
        # Guardar en BD (inyectado)
        self.repository.save_prediction(prediction_data)
        
        return PredictionOutput(
            risk_level=prediction_data["risk_level"],
            probability=prediction_data["probability"]
        )

# --- Dependencias ---
def get_db_session():
    """Generador de sesiones para inyecci√≥n"""
    with db_config.get_session() as session:
        yield session

def get_prediction_service(
    db: Session = Depends(get_db_session)
) -> IPredictionService:
    """Inyecci√≥n del servicio que cumple LSP"""
    return LDAPredictionService(
        model_repository=PredictionRepository(db)
    )

# --- Endpoint ---
@router.post("/", response_model=PredictionOutput)
async def predict(
    input_data: PredictionInput,
    prediction_service: IPredictionService = Depends(get_prediction_service)
):
    logger.info("üì• Recibida nueva solicitud de predicci√≥n")
    try:
        result = await prediction_service.predict(input_data)
        logger.info("‚úÖ Predicci√≥n completada exitosamente")
        return result
    except ValueError as e:
        logger.error(f"‚ùå Error de validaci√≥n: {str(e)}", exc_info=True)
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"‚ùå Error interno: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail="Ocurri√≥ un error procesando la solicitud"
        )