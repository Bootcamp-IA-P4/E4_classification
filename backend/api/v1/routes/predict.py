from fastapi import APIRouter, HTTPException, Depends
import joblib
from models.schemas import PredictionInput, PredictionOutput
from core.logging_config import setup_logger
from db.database import db_config
from db.repositories import PredictionRepository
from typing import Protocol, runtime_checkable
from sqlalchemy.orm import Session
from core.config import settings

router = APIRouter(prefix="/predict", tags=["predictions"])
logger = setup_logger(__name__)

# --- Abstracci√≥n para el principio Liskov ---
@runtime_checkable
class IPredictionService(Protocol):
    async def predict(self, input_data: PredictionInput) -> PredictionOutput:
        ...

# Implementaci√≥n concreta compatible con LSP
class LDAPredictionService:
    def __init__(self, model_repository: PredictionRepository):
        """Inicializa el servicio con un repositorio inyectado"""
        self.repository = model_repository
    
    async def predict(self, input_data: PredictionInput) -> PredictionOutput:
        """Implementaci√≥n espec√≠fica para modelo LDA"""
        logger.info("üîç Procesando predicci√≥n con modelo LDA...")
        
        # Aqu√≠ ir√≠a tu l√≥gica actual de make_prediction()
        # Convertir nombres al formato en ingl√©s
        technical_data = input_data.to_english_dict()

        # Simulaci√≥n de predicci√≥n (deber√≠as usar `technical_data` aqu√≠)
        prediction_data = {
            "probability": 0.85,
            "prediction_result": 1
        }

        # Guardar en BD usando campos t√©cnicos en ingl√©s
        self.repository.save_prediction(technical_data | prediction_data)

        
        # Guardar en BD (inyectado)
        #self.repository.save_prediction(prediction_data)
        
        return PredictionOutput(
            risk_level="high" if prediction_data["prediction_result"] == 1 else "low",
            probability=prediction_data["probability"]
        )

# --- Dependencias ---
def get_db_session():
    """Generador de sesiones para inyecci√≥n"""
    with db_config.get_session() as session:
        yield session

def get_prediction_service(db: Session = Depends(get_db_session)) -> IPredictionService:
    """Inyecci√≥n del servicio que cumple LSP"""
    return LDAPredictionService(
        model_repository=PredictionRepository(db)
    )

# --- Endpoint ---
@router.post("/", response_model=PredictionOutput)
async def predict(
    input_data: PredictionInput,
    prediction_service: IPredictionService = Depends(get_prediction_service)
):
    logger.info("üì• Recibida nueva solicitud de predicci√≥n")
    try:
        # Loggear los datos recibidos
        logger.debug(f"Datos recibidos: {input_data.model_dump()}")
        
        result = await prediction_service.predict(input_data)
        logger.info("‚úÖ Predicci√≥n completada exitosamente")
        return result
        
    except ValueError as e:
        logger.error(f"‚ùå Error de validaci√≥n: {str(e)}", exc_info=True)
        raise HTTPException(status_code=422, detail=str(e))
    except Exception as e:
        logger.error(f"‚ùå Error interno en el servidor", exc_info=True)  # Log completo del error
        raise HTTPException(
            status_code=500,
            detail=f"Error detallado: {str(e)}"  # Mostrar el error real
        )